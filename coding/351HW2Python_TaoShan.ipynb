{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os # used for navigating to image path\n",
    "import imageio # used for writing images\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "\n",
    "#  Keras preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Keras modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Lambda , Dense, Flatten, Dropout, Conv2D, MaxPool2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', error_bad_lines=False, sep = '\\t')\n",
    "test = pd.read_csv('test.csv', error_bad_lines=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>label</th>\n",
       "      <th>productname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2653</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Murcia Women Leather Office Grey Bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55997</td>\n",
       "      <td>Others</td>\n",
       "      <td>Colorbar Velvet Matte Temptation Lipstick 24MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2640</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Carlton London Men Brown Formal Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40565</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>W Women Maroon Kurta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38932</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Gini and Jony Girls Pink Leggings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imageid       label                                     productname\n",
       "0     2653        Bags            Murcia Women Leather Office Grey Bag\n",
       "1    55997      Others  Colorbar Velvet Matte Temptation Lipstick 24MA\n",
       "2     2640       Shoes           Carlton London Men Brown Formal Shoes\n",
       "3    40565     Topwear                            W Women Maroon Kurta\n",
       "4    38932  Bottomwear               Gini and Jony Girls Pink Leggings"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['image'] = train.apply(lambda row: str(row['imageid']) + \".jpg\", axis=1)\n",
    "test['image'] = test.apply(lambda row: str(row['imageid']) + \".jpg\", axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'images/'\n",
    "batch_size = 40\n",
    "target_size = (100,100)\n",
    "epochs = 40\n",
    "num_train_samples = train.shape[0]\n",
    "num_test_samples = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40441 validated image filenames belonging to 13 classes.\n",
      "Found 0 validated image filenames belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "#image_generator = ImageDataGenerator(rescale=1/255)\n",
    "image_generator_test = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "training_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=path,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"label\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "test_generator = image_generator_test.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    directory=path,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"label\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    subset=\"validation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model\n",
    "\n",
    "Input -> conv2d -> conv2d -> maxpool2d -> dropout -> conv2d -> conv2d -> maxpool2d -> dropout -> flatten -> dropout -> dense -> dropout -> dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 97, 97, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 94, 94, 32)        16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 32)        16416     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 41, 41, 32)        16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 3,330,189\n",
      "Trainable params: 3,330,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(100, 100, 1)),\n",
    "        Conv2D(32, kernel_size=(4, 4), activation=\"relu\"),\n",
    "        Conv2D(32, kernel_size=(4, 4), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.1),\n",
    "        Conv2D(32, kernel_size=(4, 4), activation=\"relu\"),\n",
    "        Conv2D(32, kernel_size=(4, 4), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.1),\n",
    "        Flatten(),\n",
    "        Dropout(0.1),\n",
    "        Dense(256, activation = \"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(13, activation=\"softmax\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          epochs=1,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24937\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1011/1011 [==============================] - 1531s 2s/step - loss: 0.1994 - accuracy: 0.4724\n",
      "Epoch 2/5\n",
      "1011/1011 [==============================] - 1636s 2s/step - loss: 0.1191 - accuracy: 0.6985\n",
      "Epoch 3/5\n",
      "  17/1011 [..............................] - ETA: 30:08 - loss: 0.1038 - accuracy: 0.7373"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-77d3ded28a4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#verbose=1,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         validation_steps=num_test_samples // batch_size)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        training_generator,\n",
    "        steps_per_epoch=num_train_samples // batch_size,\n",
    "        epochs=5,\n",
    "        #verbose=1,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=num_test_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = keras.model.predict_classes(test_x, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-19-6aaf1f276005>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-6aaf1f276005>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "img = load_img('images/1163.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (80, 60, 3)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 80, 60, 3)\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='shirt', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b1f14bb1f3d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['image'] = df.apply(lambda row: str(row['id']) + \".jpg\", axis=1)\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='shirt', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6759dae003f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m training_generator = image_generator.flow_from_dataframe(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDATASET_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"images\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"subCategory\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_generator' is not defined"
     ]
    }
   ],
   "source": [
    "training_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=DATASET_PATH + \"images\",\n",
    "    x_col=\"image\",\n",
    "    y_col=\"subCategory\",\n",
    "    target_size=(96,96),\n",
    "    batch_size=batch_size,\n",
    "    subset=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=60x80 at 0x29FDC8FF488>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_img('images/1163.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_from_directory('images/', labels='inferred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
